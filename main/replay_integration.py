"""
Module T√≠ch h·ª£p D·ªÖ d√†ng cho C·∫£i ti·∫øn Scalable Replay
===================================================

Module n√†y cung c·∫•p c√°c h√†m t√≠ch h·ª£p ƒë∆°n gi·∫£n ƒë·ªÉ n√¢ng c·∫•p
vul_main2.py hi·ªán c√≥ v·ªõi kh·∫£ nƒÉng replay c√≥ th·ªÉ m·ªü r·ªông.

C√°ch s·ª≠ d·ª•ng:
1. Import module n√†y trong vul_main2.py
2. Thay th·∫ø vi·ªác ch·ªçn replay hi·ªán c√≥ b·∫±ng phi√™n b·∫£n n√¢ng cao
3. Ch·ªâ c·∫ßn thay ƒë·ªïi t·ªëi thi·ªÉu code

T√°c gi·∫£: AI Assistant
"""

import torch
import numpy as np
from collections import Counter
from scalable_replay_improvements import (
    ScalableReplayManager, 
    create_scalable_replay_manager,
    GradientBasedSampleImportance
)


class EnhancedReplaySelector:
    """
    Thay th·∫ø tr·ª±c ti·∫øp cho vi·ªác ch·ªçn replay hi·ªán c√≥ v·ªõi c√°c c·∫£i ti·∫øn c√≥ th·ªÉ m·ªü r·ªông
    """
    def __init__(self, 
                 similarity_threshold=0.85,
                 max_code_lines=10,
                 n_clusters=10,
                 memory_dir="long_term_memory",
                 use_gradient_importance=False):
        
        self.replay_manager = create_scalable_replay_manager({
            'similarity_threshold': similarity_threshold,
            'max_code_lines': max_code_lines,
            'n_clusters': n_clusters,
            'memory_dir': memory_dir
        })
        
        self.use_gradient_importance = use_gradient_importance
        self.gradient_importance = None
        
    def select_enhanced_replay_samples(self, 
                                     prompt_model, 
                                     dataloader, 
                                     examples, 
                                     num_samples, 
                                     task_id,
                                     min_samples_per_class=2,
                                     current_task_examples=None):
        """
        Ch·ªçn m·∫´u replay n√¢ng cao v·ªõi t·∫•t c·∫£ c√°c c·∫£i ti·∫øn
        
        Args:
            prompt_model: Model ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
            dataloader: DataLoader cho c√°c examples tr∆∞·ªõc ƒë√≥
            examples: Danh s√°ch InputExample objects
            num_samples: S·ªë l∆∞·ª£ng m·∫´u c·∫ßn ch·ªçn
            task_id: ID task hi·ªán t·∫°i
            min_samples_per_class: S·ªë m·∫´u t·ªëi thi·ªÉu m·ªói class
            current_task_examples: Examples t·ª´ task hi·ªán t·∫°i (ƒë·ªÉ ph√¢n t√≠ch vulnerability)
            
        Returns:
            selected_indices: Ch·ªâ s·ªë c·ªßa c√°c m·∫´u ƒë∆∞·ª£c ch·ªçn
            selection_info: Th√¥ng tin chi ti·∫øt v·ªÅ qu√° tr√¨nh ch·ªçn
        """
        print(f"\nüöÄ CH·ªåN REPLAY N√ÇNG CAO CHO TASK {task_id}")
        print(f"{'='*70}")
        
        # Tr√≠ch xu·∫•t features s·ª≠ d·ª•ng t√≠nh to√°n Mahalanobis hi·ªán c√≥
        mahalanobis_distances, all_features, all_cwe_ids = self._compute_features(
            prompt_model, dataloader
        )
        
        # L·∫•y vulnerabilities c·ªßa task hi·ªán t·∫°i ƒë·ªÉ t√≠nh to√°n ∆∞u ti√™n
        current_task_vulnerabilities = set()
        if current_task_examples:
            current_task_vulnerabilities = set([ex.tgt_text for ex in current_task_examples])
        
        # S·ª≠ d·ª•ng scalable replay manager ƒë·ªÉ x·ª≠ l√Ω
        selected_examples, selection_info = self.replay_manager.process_replay_buffer(
            examples=examples,
            features=np.array(all_features),
            labels=all_cwe_ids,
            task_id=task_id,
            replay_budget=num_samples,
            current_task_vulnerabilities=current_task_vulnerabilities,
            min_samples_per_class=min_samples_per_class
        )
        
        # √Ånh x·∫° ng∆∞·ª£c v·ªÅ ch·ªâ s·ªë ban ƒë·∫ßu
        selected_indices = selection_info['selection_indices']
        
        # T√πy ch·ªçn: S·ª≠ d·ª•ng gradient-based importance
        if self.use_gradient_importance and hasattr(self, 'gradient_importance'):
            selected_indices = self._refine_with_gradient_importance(
                selected_indices, mahalanobis_distances, num_samples
            )
        
        # In th·ªëng k√™ ch·ªçn l·ª±a
        self._print_selection_stats(selection_info, all_cwe_ids, selected_indices)
        
        return selected_indices, selection_info
    
    def _compute_features(self, prompt_model, dataloader):
        """T√≠nh to√°n features s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p Mahalanobis hi·ªán c√≥"""
        prompt_model.eval()
        all_features = []
        all_cwe_ids = []

        with torch.no_grad():
            for inputs in dataloader:
                cwe_ids = inputs['tgt_text']
                if torch.is_tensor(cwe_ids):
                    all_cwe_ids.extend(cwe_ids.cpu().tolist())
                else:
                    all_cwe_ids.extend(cwe_ids)
                    
                if torch.cuda.is_available():
                    inputs = inputs.cuda()
                    
                logits = prompt_model(inputs)
                all_features.append(logits.cpu().numpy())

        all_features = np.concatenate(all_features, axis=0)
        
        # T√≠nh to√°n Mahalanobis distances ƒë·ªÉ t∆∞∆°ng th√≠ch
        mean_features = np.mean(all_features, axis=0)
        cov_matrix = np.cov(all_features, rowvar=False)
        cov_inv = np.linalg.inv(cov_matrix + np.eye(cov_matrix.shape[0]) * 1e-6)
        
        from scipy.spatial import distance
        mahalanobis_distances = [
            distance.mahalanobis(f, mean_features, cov_inv) for f in all_features
        ]
        
        return mahalanobis_distances, all_features, all_cwe_ids
    
    def _refine_with_gradient_importance(self, selected_indices, mahalanobis_distances, num_samples):
        """Tinh ch·ªânh vi·ªác ch·ªçn l·ª±a s·ª≠ d·ª•ng gradient-based importance"""
        if not hasattr(self, 'gradient_norms') or len(self.gradient_norms) == 0:
            return selected_indices
            
        # K·∫øt h·ª£p Mahalanobis distance v·ªõi gradient importance
        combined_scores = []
        for i in selected_indices:
            mahal_score = mahalanobis_distances[i] if i < len(mahalanobis_distances) else 0
            grad_score = self.gradient_norms[i] if i < len(self.gradient_norms) else 0
            combined_score = 0.7 * mahal_score + 0.3 * grad_score  # K·∫øt h·ª£p c√≥ tr·ªçng s·ªë
            combined_scores.append((i, combined_score))
        
        # S·∫Øp x·∫øp theo ƒëi·ªÉm k·∫øt h·ª£p v√† ch·ªçn top samples
        combined_scores.sort(key=lambda x: x[1], reverse=True)
        refined_indices = [i for i, _ in combined_scores[:num_samples]]
        
        return refined_indices
    
    def _print_selection_stats(self, selection_info, all_cwe_ids, selected_indices):
        """In th·ªëng k√™ ch·ªçn l·ª±a chi ti·∫øt"""
        print(f"\nüìä TH·ªêNG K√ä CH·ªåN L·ª∞A:")
        print(f"  M·∫´u ban ƒë·∫ßu: {selection_info['original_count']}")
        print(f"  Sau l·ªçc: {selection_info['after_filtering']}")
        print(f"  Sau t√≥m t·∫Øt: {selection_info['after_summarization']}")
        print(f"  Cu·ªëi c√πng ƒë∆∞·ª£c ch·ªçn: {selection_info['final_selected']}")
        
        # Ph√¢n b·ªë class trong c√°c m·∫´u ƒë∆∞·ª£c ch·ªçn
        selected_labels = [all_cwe_ids[i] for i in selected_indices if i < len(all_cwe_ids)]
        class_dist = Counter(selected_labels)
        
        print(f"\nüìà PH√ÇN B·ªê CLASS TRONG REPLAY BUFFER:")
        for class_label, count in class_dist.most_common(10):
            percentage = (count / len(selected_labels)) * 100 if len(selected_labels) > 0 else 0
            print(f"  Class {class_label}: {count} m·∫´u ({percentage:.1f}%)")
        
        print(f"{'='*70}\n")
    
    def enable_gradient_importance(self, prompt_model, loss_fn):
        """B·∫≠t t√≠nh to√°n gradient-based importance"""
        self.use_gradient_importance = True
        self.gradient_importance = GradientBasedSampleImportance(prompt_model)
        print("‚úÖ ƒê√£ b·∫≠t gradient-based importance")
    
    def get_historical_context(self, task_id):
        """L·∫•y ng·ªØ c·∫£nh l·ªãch s·ª≠ ƒë·ªÉ prompting"""
        return self.replay_manager.get_historical_context(task_id)


def upgrade_existing_replay_function():
    """
    Tr·∫£ v·ªÅ phi√™n b·∫£n n√¢ng c·∫•p c·ªßa h√†m ch·ªçn replay hi·ªán c√≥
    
    C√°ch s·ª≠ d·ª•ng trong vul_main2.py:
        # Thay th·∫ø l·ªùi g·ªçi h√†m hi·ªán c√≥
        # C≈®:
        # indices_to_replay, _ = select_uncertain_samples_with_stratified_class(...)
        
        # M·ªöI:
        enhanced_selector = upgrade_existing_replay_function()
        indices_to_replay, selection_info = enhanced_selector.select_enhanced_replay_samples(...)
    """
    return EnhancedReplaySelector(
        similarity_threshold=0.85,  # ƒêi·ªÅu ch·ªânh theo nhu c·∫ßu
        max_code_lines=10,         # Gi·∫£m ƒë·ªô d√†i code ƒë·ªÉ ti·∫øt ki·ªám memory
        n_clusters=10,             # S·ªë clusters ƒë·ªÉ t√≠nh to√°n ∆∞u ti√™n
        memory_dir="long_term_memory",
        use_gradient_importance=False  # ƒê·∫∑t True ƒë·ªÉ tinh ch·ªânh d·ª±a tr√™n gradient
    )


# C√°c h√†m h·ªó tr·ª£ t√≠ch h·ª£p
def create_enhanced_template_with_history(original_template_text, historical_context=""):
    """
    T·∫°o template n√¢ng cao bao g·ªìm ng·ªØ c·∫£nh l·ªãch s·ª≠
    
    Args:
        original_template_text: Text template ban ƒë·∫ßu
        historical_context: Ng·ªØ c·∫£nh l·ªãch s·ª≠ t·ª´ long-term memory
        
    Returns:
        enhanced_template_text: Template v·ªõi ng·ªØ c·∫£nh l·ªãch s·ª≠
    """
    if not historical_context:
        return original_template_text
    
    enhanced_template = f"""
    {historical_context}
    
    Task hi·ªán t·∫°i: {original_template_text}
    """
    
    return enhanced_template


def log_replay_improvements(selection_info, task_id, log_file="replay_improvements.log"):
    """
    Ghi log th·ªëng k√™ c·∫£i ti·∫øn replay ƒë·ªÉ ph√¢n t√≠ch
    
    Args:
        selection_info: Th√¥ng tin t·ª´ vi·ªác ch·ªçn replay n√¢ng cao
        task_id: ID task hi·ªán t·∫°i
        log_file: ƒê∆∞·ªùng d·∫´n file log
    """
    import json
    import datetime
    
    log_entry = {
        'timestamp': datetime.datetime.now().isoformat(),
        'task_id': task_id,
        'selection_info': selection_info,
        'improvements': {
            'redundancy_reduction': selection_info['original_count'] - selection_info['after_filtering'],
            'summarization_applied': True,
            'clustering_priority_used': True,
            'long_term_memory_stored': True
        }
    }
    
    with open(log_file, 'a') as f:
        f.write(json.dumps(log_entry) + '\n')


# V√≠ d·ª• code t√≠ch h·ª£p cho vul_main2.py
INTEGRATION_EXAMPLE = """
# Th√™m v√†o ƒë·∫ßu file vul_main2.py sau c√°c imports hi·ªán c√≥
from replay_integration import upgrade_existing_replay_function, log_replay_improvements

# Thay th·∫ø code ch·ªçn replay hi·ªán c√≥ (kho·∫£ng d√≤ng 700) b·∫±ng:
if i > 1:  # Cho c√°c tasks sau task ƒë·∫ßu ti√™n
    # ... code hi·ªán c√≥ cho prev_examples v√† train_dataloader_prev ...
    
    # CH·ªåN REPLAY N√ÇNG CAO - Thay th·∫ø select_uncertain_samples_with_stratified_class hi·ªán c√≥
    enhanced_selector = upgrade_existing_replay_function()
    
    # L·∫•y examples task hi·ªán t·∫°i ƒë·ªÉ ph√¢n t√≠ch vulnerability
    current_examples = read_prompt_examples(data_paths[i - 1])
    
    # Ch·ªçn l·ª±a n√¢ng cao v·ªõi t·∫•t c·∫£ c·∫£i ti·∫øn
    indices_to_replay, selection_info = enhanced_selector.select_enhanced_replay_samples(
        prompt_model=prompt_model,
        dataloader=train_dataloader_prev,
        examples=prev_examples,
        num_samples=replay_budget,
        task_id=i,
        min_samples_per_class=args.min_samples_per_class,
        current_task_examples=current_examples
    )
    
    # Ghi log c·∫£i ti·∫øn ƒë·ªÉ ph√¢n t√≠ch
    log_replay_improvements(selection_info, i)
    
    # T√πy ch·ªçn: L·∫•y ng·ªØ c·∫£nh l·ªãch s·ª≠ ƒë·ªÉ prompting n√¢ng cao
    historical_context = enhanced_selector.get_historical_context(i)
    if historical_context:
        print(f"Ng·ªØ c·∫£nh l·ªãch s·ª≠ cho Task {i}:")
        print(historical_context)
    
    # ... ph·∫ßn c√≤n l·∫°i c·ªßa code hi·ªán c√≥ gi·ªØ nguy√™n ...
"""

if __name__ == "__main__":
    print("Module T√≠ch h·ª£p Scalable Replay")
    print("===============================")
    print("\nƒê·ªÉ t√≠ch h·ª£p v·ªõi code hi·ªán c√≥:")
    print(INTEGRATION_EXAMPLE)